//imp rdd = list -> playing with list.
      df = schema on rdd (metadata)
      spark.sql -> data and schema ar diff places consider example of External Tables

//to come from higher level df to rdd and use rdd methods syntax is  - df.rdd.rddfuncs
1. sparkContext(sc) comes inside spark and it is the entry point to all the worker nodes where as saprksession is teh entry point for spark
    SparkContext is the entry point to low-level RDD operations and cluster communication.
    SparkSession is the higher-level unified entry point to Spark, including SQL, DataFrame, Dataset, and also exposes SparkContext internally.
2. parallelize(iterable) //this doest give df but just transfer sthe data from driver node to worker
3. .toDF([lit of col]) or .createDF(rdd)
4. .collect()/take/show get the result from worker to driver node //every action send te result from worker node to driver node
5. we can also use .take(no of records to display)
6. for 
   rdd - rdd.getNumPartitions() to get the no of partitions
   df - df.rdd.getNumPartitions() to get the no of partitions
7. there are 2 properties 1. defaultParallelism 2. defaultMinPartitions //note these are properties nt methods
Imp Methods - 
    1. flatmap
    2. map
    3. reducebykey
    4. sortby - works for key, value pair or even on a single iterable using lambda 
    5. sortbykey - wroks only on key, value pair with no arquements ex:- .sortbykey(True/False)
    6. reduce
    7. filter
    8. distinct
    9. count - if it is an dirct action hence no shuffle
    10. coubtByValue() is an action like reduce but with out lambda method is used to replace map+recudeBykeY and output is got in dict format 
        ***and very imp it is an action hence plan is same as count
    11. groupByKey() no parameter just give 2 items in pair as input
    12. rdd = rdd.repartition(10)
    13. rdd = rdd.coalesce(10)
12. rdd1.join(rdd2) -  //join is a wide transformation
    here we have a problem there is a shuffle which is costly hence use boradcasting
    broadcasting var or broadcasting join - 
    but to do boradcasting, you cannot do it in worker node you have to do it from driver node - 
    so you can use an action as action returns df/scalar value to driver program
    sytax - final = spark.sc.broadcast(smallrdd.collect())
    and nothing to further also advantage of bradcadting is no shuffle at all hence broadcasting is a narrow transformation
13. caching in rdd and df is lazy but in spark sql by default it is eager we can change it to lazy also.
14. spark.sparkContext.textFile('path')
15. rdd.saveAsTextFile('path not present')

Final:-
1. reduce is an action takes 2 parameter
2. reduceByKey is an transformation takes 2 parameter
3. groupByKey is an transformation takes no parameter - returns and iterable as value
4. sortBy is an transformation takes n no of parameter but sorts like sorted() in py 
5. sortByKey is an transformation takes no parameter but can pass ascending=
6. countbyvalue() is an transformation no parameter
7. filter you know
8. map you know
9. flatmap you know
10. distinct you know
11. count,take,collect,show- same

repartition vs coalesce in Spark
repartition(n)
Always involves a full shuffle.
Tries to evenly distribute records across partitions.
Can be used to increase or decrease the number of partitions.
Because of the shuffle, it’s more expensive, but results in balanced partition sizes.
Internally, repartition is equivalent to:
coalesce(n, shuffle = true)

coalesce(n)
By default, does NOT shuffle.
Typically used to reduce the number of partitions.
It works by collapsing multiple parent partitions into fewer ones.
Since there’s no shuffle, data is not evenly redistributed, so uneven partition sizes can occur.
Much cheaper than repartition when shrinking partitions.

Key takeaways
To increase partitions → you must use repartition (coalesce can’t do this without shuffle).

To decrease partitions:
Use coalesce if you want better performance and can tolerate uneven partitions.
Use repartition if you need evenly sized partitions.

Conceptually:
repartition = shuffle + rebalance
coalesce = merge partitions (no shuffle)