1. we can create a table view using df- 
    df.createOrReplaceTempView('table name')
    new df = spark.sql('select * from table name') //temp view table can be accessed using spark.sql
2. we can convert table / view to df using - 
    df = spark.read.table('orders') or 
    df = spark.sql('') or
    df = spark.table('table name')

External tables:
Data is stored in the Data Lake (S3/ADLS/etc).
Metadata is stored in Hive Metastore.
Dropping the table removes only metadata, data remains.

Managed tables:
Data is stored in /user/hive/warehouse/<db>.db/<table>/.
Metadata is stored in Hive Metastore.
Dropping the table removes both data and metadata.

| Table type | Data location                 | Metadata  | Drop table behavior |
| ---------- | ----------------------------- | --------- | ------------------- |
| Managed    | HDFS (`/user/hive/warehouse`) | Metastore | Data deleted        |
| External   | Any HDFS path                 | Metastore | Data preserved      |
